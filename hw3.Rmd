---
title: "Course evaluations"
author:
- Add Author 1
- Add Author 2
- Add Author 3
- Add Author 4
output: 
  html_document: 
    highlight: pygments
    theme: flatly
---

### Load packages and data

```{r message=FALSE}
library(dplyr)
library(ggplot2)
library(stringr)
library(GGally)

load(url("http://www.openintro.org/stat/data/evals.RData"))
```

## Exploratory Data Analysis

1.  Describe the distribution of `score`. Is the distribution skewed? What does 
    that tell you about how students rate courses? Is this what you expected to 
    see? Why, or why not? Include any summary statistics and visualizations
    you use in your response.

2.  Other than `score`, select two other variables and describe their distribution 
    using an appropriate visualization.

## Simple linear regression

3.  Replot the scatterplot, but this time use `geom_point(position = "jitter")`.
    What does "jitter" mean? What was misleading about the initial scatterplot?

4.  Let's see if the apparent trend in the plot is something more than
    natural variation. Fit a linear model called `m_bty` to predict average
    professor score by average beauty rating and add the regression line to your
    plot. Write out the equation for the linear model and
    interpret the slope. Does there appear to be a practically significant
    relationship between professor score and average beauty rating?

## Multiple linear regression

5.  Describe how the `str_detect` function works and how we use information
    resulting from that function to make the pairwise plot.

6.  How do the AIC and the adjusted $R^2$ of this model and the previous one
    compare? Has the addition of `gender` to the model changed the parameter
    estimate (slope) for `bty_avg`?

7.  What is the equation of the line corresponding to *just* males? (*Hint:* For
    males, the parameter estimate for the slope of`gendermale` is multiplied by 1.) 
    
8.  For two professors who received the same beauty rating, which gender tends to have the
    higher course evaluation score?
    
9.  Create a new model called `m_bty_rank` with `gender` removed and `rank` 
    added in. How is R handling a categorical variables that has more 
    than two levels? Note that the rank variable has three levels: `teaching`, 
    `tenure track`, `tenured`.

10. How does the relationship between beauty and evaluation score
    vary between male and female professors?

## The search for the best model

11. Which variable would you expect to be the worst predictor of evaluation scores?
    Why? *Hint:* Think about which variable would you expect to not have any 
    association with the professor's score.

12. Check your suspicions from the previous exercise. Include the model output
    in your response.

13. Interpret the coefficient associated with the ethnicity variable in context.

14. Drop the variable that results in the highest gain of adjusted R-squared.
    Did the coefficients and significance of the other explanatory variables change?
    (One of the things that makes multiple regression interesting is that
    coefficient estimates depend on the other variables that are included in
    the model.) If not, what does this say about whether or not the dropped
    variable was collinear with the other explanatory variables?

15. Using backward-selection and either AIC or adjusted R-squared as the selection 
    criterion, determine the *best* model. You do not need to show all steps in your
    answer, just the output for the final model. Also, write out the linear
    model for predicting score based on the final model you settle on.

16. Based on your final model, describe the characteristics of a professor and 
    course at University of Texas at Austin that would be associated with a high
    evaluation score.

17. Split your data into a training (80%) and test (20%) subsets, fit a full model to 
    the training data and use backwards selection to arrive at the *best* model and 
    use this model to calculate the rmse for both the training and test data. Are they 
    similar or are they different, what does this tell you about the quality of your model?

18. Would you be comfortable generalizing your conclusions to apply to professors
    generally (at any university)? Why or why not?
